#!/usr/bin/env python3

# Copyright (c) 2016-2019 Aleksey Cheusov <vle@gmx.net>
#
# Permission is hereby granted, free of charge, to any person obtaining
# a copy of this software and associated documentation files (the
# "Software"), to deal in the Software without restriction, including
# without limitation the rights to use, copy, modify, merge, publish,
# distribute, sublicense, and/or sell copies of the Software, and to
# permit persons to whom the Software is furnished to do so, subject to
# the following conditions:
#
# The above copyright notice and this permission notice shall be
# included in all copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
# EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
# MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
# NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE
# LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION
# OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION
# WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

import pickle
import sys
import getopt

from svmlight_loader import load_svmlight_file
from sklearn import tree

def usage():
    print('''scikit_dt-train builds the model using sklearn.tree.DecisionTreeClassifier.

Usage: scikit_dt-train [OPTIONS] <dataset> <model>

OPTIONS:

   Most options below directly correspond to the arguments of
   sklearn.tree.DecisionTreeClassifier constructor. So, for
   detailed information see scikit learn documentation.

   -h   --help                         Display this screen.
        --criterion <criterion>        The function to measure
                                       the quality of a split
                                       (default: "gini").
        --splitter <splitter>          The strategy used to choose
                                       the split at each node (default:"best")
        --max_depth <depth>            The maximum depth of the tree
                                       (default: None).
        --min_samples_split <num>      The minimum number of samples required
                                       to split an internal node
                                       (default: 2).
        --min_samples_leaf <num>       The minimum number of samples required
                                       to be at a leaf node (default: 1).
        --min_weight_fraction_leaf <weight>  The minimum weighted fraction of
                                             the sum total of weights required
                                             to be at a leaf node (default: 0)
        --max_features <num>           The number of features to consider
                                       when looking for the best split
                                       (default: None)
        --random_state <seed>          Seed for PRNG (default: None).
        --max_leaf_nodes <num>         Grow a tree with <num>
                                       in best-first fashion (default: None).
        --min_impurity_decrease <value>   A node will be split if this split
                                          induces a decrease of the impurity
                                          greater than or equal to this value
                                          (default: 0).
        --min_impurity_split <value>   Threshold for early stopping in tree
                                       growth (default: None).
        --class_weight <weights>       For now the only supported non-None
                                       value is "balanced" (default: None).
        --presort                      Enable presorting the data
                                       to speed up the finding of best
                                       splits in fitting (default: disabled).
''')

def string_to_value(s):
    if s == "None":
        return None
    elif s == "":
        return ""
    elif s[0].isdigit():
        try:
            return int(s)
        except:
            return float(s)
    else:
        return s

kwargs_constructor = {}
kwargs_fit = {}

opts,args = getopt.getopt(sys.argv[1:], 'h',
                          ['help', "criterion=", "splitter=", "max_depth=",
                           "min_samples_split=", "min_samples_leaf=",
                           "min_weight_fraction_leaf=", "max_features=",
                           "random_state=", "max_leaf_nodes=",
                           "min_impurity_decrease=", "min_impurity_split=",
                           "class_weight=", "presort" ]
)

for o,a in opts:
    if o in ("-h", "--help", ):
        usage()
        sys.exit()
    if o in ("--criterion="):
        kwargs_constructor['criterion'] = string_to_value(a)
    if o in ("--splitter="):
        kwargs_constructor['splitter'] = string_to_value(a)
    if o in ("--max_depth="):
        kwargs_constructor['max_depth'] = string_to_value(a)
    if o in ("--min_samples_split="):
        kwargs_constructor['min_samples_split'] = string_to_value(a)
    if o in ("--min_samples_leaf="):
        kwargs_constructor['min_samples_leaf'] = string_to_value(a)
    if o in ("--min_weight_fraction_leaf="):
        kwargs_constructor['min_weight_fraction_leaf'] = string_to_value(a)
    if o in ("--max_features="):
        kwargs_constructor['max_features'] = string_to_value(a)
    if o in ("--random_state="):
        kwargs_constructor['random_state'] = string_to_value(a)
    if o in ("--max_leaf_nodes="):
        kwargs_constructor['max_leaf_nodes'] = string_to_value(a)
    if o in ("--min_impurity_decrease="):
        kwargs_constructor['min_impurity_decrease'] = string_to_value(a)
    if o in ("--min_impurity_split="):
        kwargs_constructor['min_impurity_split'] = string_to_value(a)
    if o in ("--class_weight="):
        kwargs_constructor['class_weight'] = string_to_value(a)
    if o in ("--presort"):
        kwargs_constructor['presort'] = True

X_train, y_train = load_svmlight_file(args[0])

clf = tree.DecisionTreeClassifier(**kwargs_constructor)

clf.fit(X_train, y_train)

with open(args[1], 'wb') as f:
    pickle.dump(clf, f)
    pickle.dump(X_train.shape[1], f)
